import asyncio
import aiohttp
import json
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
TOKEN = "8464793187:AAFd3MNyXWwX4g9bAZrPvVEVrZcz0GqcbjA"
AI_KEY = "AIzaSyDgW7ONTdXO_yiVTYlGs4Y_Q5VaGP0sano"

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ë–æ—Ç
bot = Bot(token=TOKEN)
dp = Dispatcher()

async def get_available_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={AI_KEY}"
    
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as resp:
            if resp.status == 200:
                data = await resp.json()
                models = data.get('models', [])
                print("\nüìã –î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò Gemini:")
                for model in models:
                    if 'generateContent' in model.get('supportedGenerationMethods', []):
                        print(f"‚Ä¢ {model['name']} (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç generateContent)")
                return models
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {resp.status}")
                return []

async def get_ai_prediction(match_name):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç Gemini AI"""
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    models_to_try = [
        "gemini-1.5-pro-latest",     # –°–∞–º–∞—è –º–æ—â–Ω–∞—è
        "gemini-1.0-pro-latest",     # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è
        "gemini-1.0-pro",           # –ë–∞–∑–æ–≤–∞—è
        "gemini-1.5-flash-001",     # –ë—ã—Å—Ç—Ä–∞—è
        "gemini-1.0-ultra-latest"   # –ü—Ä–µ–º–∏—É–º
    ]
    
    headers = {"Content-Type": "application/json"}
    
    for model_name in models_to_try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={AI_KEY}"
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": f"–¢—ã —Ñ—É—Ç–±–æ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–∞—Ç—á '{match_name}'. –ö—Ç–æ –ø–æ–±–µ–¥–∏—Ç –∏ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Å—á–µ—Ç? –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."
                }]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 150
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers, timeout=10) as resp:
                    data = await resp.json()
                    
                    if resp.status == 200:
                        if 'candidates' in data and len(data['candidates']) > 0:
                            prediction = data['candidates'][0]['content']['parts'][0]['text']
                            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
                            return prediction
                    
                    # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ 404, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                    if resp.status == 404:
                        logger.warning(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é...")
                        continue
                        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model_name}: {e}")
            continue
    
    # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
    return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ API –∏–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."

@dp.message(Command("start"))
async def start_cmd(message: types.Message):
    await message.answer(
        "‚öΩ –§—É—Ç–±–æ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –±–æ—Ç –≥–æ—Ç–æ–≤!\n\n"
        "–ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ç—á–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ –≠–≤–µ—Ä—Ç–æ–Ω –õ–∏–¥—Å\n"
        "‚Ä¢ –ë–∞—Ä—Å–µ–ª–æ–Ω–∞ –†–µ–∞–ª\n"
        "‚Ä¢ –ê—Ä—Å–µ–Ω–∞–ª –ß–µ–ª—Å–∏\n\n"
        "–Ø –¥–∞–º –∫—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –º–∞—Ç—á."
    )

@dp.message(Command("models"))
async def models_cmd(message: types.Message):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    await message.answer("üîÑ –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini...")
    
    models = await get_available_models()
    if models:
        supported_models = []
        for model in models:
            if 'generateContent' in model.get('supportedGenerationMethods', []):
                model_name = model['name'].split('/')[-1]
                supported_models.append(model_name)
        
        if supported_models:
            response = "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n" + "\n".join([f"‚Ä¢ {model}" for model in supported_models[:10]])
            await message.answer(response)
        else:
            await message.answer("‚ùå –ù–µ—Ç –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π generateContent")
    else:
        await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")

@dp.message()
async def handle_message(message: types.Message):
    if not message.text or message.text.startswith('/'):
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç"
    await bot.send_chat_action(message.chat.id, "typing")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
    prediction = await get_ai_prediction(message.text)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    response = f"‚öΩ **–ú–∞—Ç—á:** {message.text}\n\n{prediction}"
    await message.answer(response, parse_mode="Markdown")

async def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    print("=" * 50)
    print("üöÄ –ó–ê–ü–£–°–ö –§–£–¢–ë–û–õ–¨–ù–û–ì–û –ë–û–¢–ê")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    print("\nüîç –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Gemini API...")
    await get_available_models()
    
    # –£–¥–∞–ª—è–µ–º –≤–µ–±—Ö—É–∫
    await bot.delete_webhook(drop_pending_updates=True)
    print("‚úÖ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
    print("üì± –û—Ç–ø—Ä–∞–≤—å—Ç–µ /start –≤ Telegram")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º polling
    try:
        await dp.start_polling(bot, skip_updates=True)
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(main())
